{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chatbots 101\n",
    "\n",
    "In this chapter, you'll learn how to build your first chatbot. After gaining a bit of historical context, you'll set up a basic structure for receiving text and responding to users, and then learn how to add the basic elements of personality. You'll then build rule-based systems for parsing text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EchoBot I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return bot_message\n",
    "\n",
    "# Test function\n",
    "print(respond(\"hello!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EchoBot II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create templates\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChitChat - (Smalltalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary with the predefined responses\n",
    "responses = {\n",
    "  \"what's your name?\": \"my name is {0}\".format(name),\n",
    "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
    "  \"default\": \"default message\"\n",
    "}\n",
    "\n",
    "# Return the matching response if there is one, default otherwise\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return the matching message\n",
    "        bot_message = responses[message]\n",
    "    else:\n",
    "        # Return the \"default\" message\n",
    "        bot_message = responses[\"default\"]\n",
    "    return bot_message\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"what's today's weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random module\n",
    "import random\n",
    "\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary containing a list of responses for each message\n",
    "responses = {\n",
    "  \"what's your name?\": [\n",
    "      \"my name is {0}\".format(name),\n",
    "      \"they call me {0}\".format(name),\n",
    "      \"I go by {0}\".format(name)\n",
    "   ],\n",
    "  \"what's today's weather?\": [\n",
    "      \"the weather is {0}\".format(weather),\n",
    "      \"it's {0} today\".format(weather)\n",
    "    ],\n",
    "  \"default\": [\"default message\"]\n",
    "}\n",
    "\n",
    "# Use random.choice() to choose a matching response\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return a random matching response\n",
    "        bot_message = random.choice(responses[message])\n",
    "    else:\n",
    "        # Return a random \"default\" response\n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"what's today's weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA I: asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def respond(message):\n",
    "    # Check for a question mark\n",
    "    if message.endswith(\"?\"):\n",
    "        # Return a random question\n",
    "        return random.choice(responses[\"question\"])\n",
    "    # Return a random statement\n",
    "    return random.choice(responses[\"statement\"])\n",
    "\n",
    "\n",
    "# Send messages ending in a question mark\n",
    "send_message(\"what's today's weather?\")\n",
    "send_message(\"what's today's weather?\")\n",
    "\n",
    "# Send messages which don't end with a question mark\n",
    "send_message(\"I love building chatbots\")\n",
    "send_message(\"I love building chatbots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA II: Extracting key phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return response.format(phrase)\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA III: Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my', 'your', message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your', 'my', message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you', 'me', message)\n",
    "\n",
    "    return message\n",
    "\n",
    "print(replace_pronouns(\"my last birthday\"))\n",
    "print(replace_pronouns(\"when you went to Florida\"))\n",
    "print(replace_pronouns(\"I had my own castle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA IV: Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(rules, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return response\n",
    "\n",
    "# Send the messages\n",
    "send_message(\"do you remember your last birthday\")\n",
    "send_message(\"do you think humans should be worried about AI\")\n",
    "send_message(\"I want a robot friend\")\n",
    "send_message(\"what if you could be anything you wanted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understanding natural language\n",
    "\n",
    "Here, you'll use machine learning to turn natural language into structured data using spaCy, scikit-learn, and rasa NLU. You'll start with a refresher on the theoretical foundations and then move onto building models using the ATIS dataset, which contains thousands of sentences from real people interacting with a flight booking system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with regex I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll begin by implementing a very simple technique to recognize intents - looking for the presence of keywords.\n",
    "\n",
    "A dictionary, keywords, has already been defined. It has the intents \"greet\", \"goodbye\", and \"thankyou\" as keys, and lists of keywords as the corresponding values. For example, keywords[\"greet\"] is set to \"[\"hello\",\"hi\",\"hey\"].\n",
    "\n",
    "Also defined is a second dictionary, responses, indicating how the bot should respond to each of these intents. It also has a default response with the key \"default\".\n",
    "\n",
    "The function send_message(), along with the bot and user templates, have also already been defined. Your job in this exercise is to create a dictionary with the intents as keys and regex objects as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with regex II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your patterns dictionary created, it's now time to define a function to find the intent of a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction with regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll use another simple method, this time for finding a person's name in a sentence, such as \"hello, my name is David Copperfield\".\n",
    "\n",
    "You'll look for the keywords \"name\" or \"call(ed)\", and find capitalized words using regex and assume those are names. Your job in this exercise is to define a find_name() function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(r'name|call')\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile('[A-Z]{1}[a-z]*').findall(message)\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word vectors with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the spaCy English model by calling spacy.load() with argument 'en'.\n",
    "Calculate the length of sentences using len() and the dimensionality of the word vectors using nlp.vocab.vectors_length.\n",
    "For each sentence, call the nlp object with the sentence as the sole argument. Store the result as doc.\n",
    "Use the .vector attribute of doc to get the vector representation of each sentence, and store this vector in the appropriate row of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a support vector classifier\n",
    "clf = SVC(C=1)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spaCy's entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define included_entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning roles using spaCy's parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the document\n",
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasa NLU\n",
    "\n",
    "In this exercise, you'll use Rasa NLU to create an interpreter, which parses incoming user messages and returns a set of entities. Your job is to train an interpreter using the MITIE entity recognition model in Rasa NLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "# Create args dictionary\n",
    "args = {\"pipeline\":\"spacy_sklearn\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUConfig(cmdline_args=args)\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"./training_data.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Test the interpreter\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-efficient entity recognition\n",
    "\n",
    "Most systems for extracting entities from text are built to extract 'Universal' things like names, dates, and places. But you probably don't have enough training data for your bot to make these systems perform well!\n",
    "\n",
    "In this exercise, you'll activate the MITIE entity recognizer inside Rasa to extract restaurants-related entities using a very small amount of training data. A dictionary args has already been defined for you, along with a training_data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "pipeline = [\n",
    "    \"nlp_spacy\",\n",
    "    \"tokenizer_spacy\",\n",
    "    \"ner_crf\"\n",
    "]\n",
    "\n",
    "# Create a config that uses this pipeline\n",
    "config = RasaNLUConfig(cmdline_args= {\"pipeline\": pipeline})\n",
    "\n",
    "# Create a trainer that uses this config\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Parse some messages\n",
    "print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "print(interpreter.parse(\"are there any good pizza places in the center?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building a virtual assistant\n",
    "\n",
    "In this chapter, you'll build a personal assistant to help you plan a trip. It will be able to respond to questions like \"are there any cheap hotels in the north of town?\" by looking inside a hotelâ€™s database for matching results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL statements in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlite3\n",
    "import sqlite3\n",
    "\n",
    "# Open connection to DB\n",
    "conn = sqlite3.connect('hotels.db')\n",
    "\n",
    "# Create a cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# Define area and price\n",
    "area, price = \"south\", \"hi\"\n",
    "t = (area, price)\n",
    "\n",
    "# Execute the query\n",
    "c.execute('SELECT * FROM hotels WHERE area=? AND price=?', t)\n",
    "\n",
    "# Print the results\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating queries from parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_hotels()\n",
    "def find_hotels(params):\n",
    "    # Create the base query\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    # Add filter clauses for each of the parameters\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params]\n",
    "        query += \" WHERE \" + \" and \".join(filters)\n",
    "    # Create the tuple of values\n",
    "    t = tuple(params.values())\n",
    "    \n",
    "    # Open connection to DB\n",
    "    conn = sqlite3.connect('hotels.db')\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Execute the query\n",
    "    c.execute(query, t)\n",
    "    # Return the results\n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your custom function to find hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary of column names and values\n",
    "params = {\n",
    "    \"area\":\"south\",\n",
    "    \"price\":\"lo\"}\n",
    "\n",
    "# Find the hotels that match the parameters\n",
    "print(find_hotels(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SQL from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Initialize an empty params dictionary\n",
    "    params = {}\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find hotels that match the dictionary\n",
    "    results = find_hotels(params)\n",
    "    # Get the names of the hotels and index of the response\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Select the nth element of the responses array\n",
    "    return responses[n].format(*names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the respond() function\n",
    "print(respond(\"I want an expensive hotel in the south of town\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining your search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a respond function, taking the message and existing params as input\n",
    "def respond(message, params):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    # Return the appropriate response\n",
    "    return responses[n].format(*names), params\n",
    "\n",
    "# Initialize params dictionary\n",
    "params = {}\n",
    "\n",
    "# Pass the messages to the bot\n",
    "for message in [\"I want an expensive hotel\", \"in the north of town\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params = respond(message, params)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic negation\n",
    "\n",
    "Quite often, you'll find your users telling you what they don't want - and that's important to understand! In general, negation is a difficult problem in NLP. Here, we'll take a very simple approach that works for many cases.\n",
    "\n",
    "A list of tests called tests has been defined for you. Explore it in the Shell - you'll find that each test is a tuple consisting of:\n",
    "\n",
    "* A string containing a message with entities.\n",
    "* A dictionary containing the entities as keys and a Boolean saying whether they are negated as the key.\n",
    "\n",
    "Your job is to define a function called negated_ents() which looks for negated entities in a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define negated_ents()\n",
    "def negated_ents(phrase):\n",
    "    # Extract the entities using keyword matching\n",
    "    ents = [e for e in [\"south\", \"north\"] if e in phrase]\n",
    "    # Find the index of the final character of each entity\n",
    "    ends = sorted([phrase.index(e) + len(e) for e in ents])\n",
    "    # Initialise a list to store sentence chunks\n",
    "    chunks = []\n",
    "    # Take slices of the sentence up to and including each entitiy\n",
    "    start = 0\n",
    "    for end in ends:\n",
    "        chunks.append(phrase[start:end])\n",
    "        start = end\n",
    "    result = {}\n",
    "    # Iterate over the chunks and look for entities\n",
    "    for chunk in chunks:\n",
    "        for ent in ents:\n",
    "            if ent in chunk:\n",
    "                # If the entity contains a negation, assign the key to be False\n",
    "                if \"not\" in chunk or \"n't\" in chunk:\n",
    "                    result[ent] = False\n",
    "                else:\n",
    "                    result[ent] = True\n",
    "    return result  \n",
    "\n",
    "# Check that the entities are correctly assigned as True or False\n",
    "for test in tests:\n",
    "    print(negated_ents(test[0]) == test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with excluded slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the respond function\n",
    "def respond(message, params, neg_params):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    ent_vals = [e[\"value\"] for e in entities]\n",
    "    # Look for negated entities\n",
    "    negated = negated_ents(message, ent_vals)\n",
    "    for ent in entities:\n",
    "        if ent[\"value\"] in negated and negated[ent[\"value\"]]:\n",
    "            neg_params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "        else:\n",
    "            params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params, neg_params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Return the correct response\n",
    "    return responses[n].format(*names), params, neg_params\n",
    "\n",
    "# Initialize params and neg_params\n",
    "params = {}\n",
    "neg_params = {}\n",
    "\n",
    "# Pass the messages to the bot\n",
    "for message in [\"I want a cheap hotel\", \"but not in the north of town\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params, neg_params = respond(message, params, neg_params)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dialogue\n",
    "\n",
    "Everything you've built so far has statelessly mapped intents to actions and responses. It's amazing how far you can get with that! But to build more sophisticated bots you will always want to add some statefulness. That's what you'll do here, as you build a chatbot that helps users order coffee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the INIT state\n",
    "INIT = 0\n",
    "\n",
    "# Define the CHOOSE_COFFEE state\n",
    "CHOOSE_COFFEE = 1\n",
    "\n",
    "# Define the ORDERED state\n",
    "ORDERED = 2\n",
    "\n",
    "# Define the policy rules\n",
    "policy = {\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (INIT, \"none\"): (INIT, \"I'm sorry - I'm not sure how to help you\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"none\"): (CHOOSE_COFFEE, \"I'm sorry - would you like Colombian or Kenyan?\"),\n",
    "}\n",
    "\n",
    "# Create the list of messages\n",
    "messages = [\n",
    "    \"I'd like to become a professional dancer\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"my favourite animal is a zebra\",\n",
    "    \"kenyan\"\n",
    "]\n",
    "\n",
    "# Call send_message() for each message\n",
    "state = INIT\n",
    "for message in messages:    \n",
    "    state = send_message(policy, state, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking contextual questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the states\n",
    "INIT=0 \n",
    "CHOOSE_COFFEE=1\n",
    "ORDERED=2\n",
    "\n",
    "# Define the policy rules dictionary\n",
    "policy_rules = {\n",
    "    (INIT, \"ask_explanation\"): (INIT, \"I'm a bot to help you order coffee beans\"),\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"ask_explanation\"): (CHOOSE_COFFEE, \"We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\")    \n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    for msg in messages:\n",
    "        state = send_message(state, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"what can you do for me?\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"what do you mean by that?\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def respond(message, params, prev_suggestions, excluded):\n",
    "    # Interpret the message\n",
    "    parse_data = interpret(message)\n",
    "    # Extract the intent\n",
    "    intent = parse_data[\"intent\"][\"name\"]\n",
    "    # Extract the entities\n",
    "    entities = parse_data[\"entities\"]\n",
    "    # Add the suggestion to the excluded list if intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        excluded.extend(prev_suggestions)\n",
    "    # Fill the dictionary with entities\t\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find matching hotels\n",
    "    results = [\n",
    "        r \n",
    "        for r in find_hotels(params, excluded) \n",
    "        if r[0] not in excluded\n",
    "    ]\n",
    "    # Extract the suggestions\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    suggestions = names[:2]\n",
    "    return responses[n].format(*names), params, suggestions, excluded\n",
    "\n",
    "# Initialize the empty dictionary and lists\n",
    "params, suggestions, excluded = {}, [], []\n",
    "\n",
    "# Send the messages\n",
    "for message in [\"I want a mid range hotel\", \"no that doesn't work for me\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params, suggestions, excluded = respond(message, params, suggestions, excluded)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending actions I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy()\n",
    "def policy(intent):\n",
    "    # Return \"do_pending\" if the intent is \"affirm\"\n",
    "    if intent == \"affirm\":\n",
    "        return \"do_pending\", None\n",
    "    # Return \"Ok\" if the intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        return \"Ok\", None\n",
    "    if intent == \"order\":\n",
    "        return \"Unfortunately, the Kenyan coffee is currently out of stock, would you like to order the Brazilian beans?\",/\n",
    "                \"Alright, I've ordered that for you!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending actions II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define send_message()\n",
    "def send_message(pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    action, pending_action = policy(interpret(message))\n",
    "    if action == \"do_pending\" and pending is not None:\n",
    "        print(\"BOT : {}\".format(pending))\n",
    "    else:\n",
    "        print(\"BOT : {}\".format(action))\n",
    "    return pending_action\n",
    "    \n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        pending = send_message(pending,msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"ok yes please\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending state transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the states\n",
    "INIT=0\n",
    "AUTHED=1\n",
    "CHOOSE_COFFEE=2\n",
    "ORDERED=3\n",
    "\n",
    "# Define the policy rules\n",
    "policy_rules = {\n",
    "    (INIT, \"order\"): (INIT, \"you'll have to log in first, what's your phone number?\", AUTHED),\n",
    "    (INIT, \"number\"): (AUTHED, \"perfect, welcome back!\", None),\n",
    "    (AUTHED, \"order\"): (CHOOSE_COFFEE, \"would you like Colombian or Kenyan?\", None),    \n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\", None)\n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-1234\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together I\n",
    "\n",
    "It's time to put everything you've learned in the course together by combining the coffee ordering bot with the ELIZA rules from chapter 1.\n",
    "\n",
    "To begin, you'll define a function called chitchat_response(), which calls the predefined function match_rule() from back in chapter 1. This returns a response if the message matched an ELIZA template, and otherwise, None.\n",
    "\n",
    "The ELIZA rules are contained in a dictionary called eliza_rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chitchat_response()\n",
    "def chitchat_response(message):\n",
    "    # Call match_rule()\n",
    "    response, phrase = match_rule(eliza_rules, message)\n",
    "    # Return none if response is \"default\"\n",
    "    if response == \"default\":\n",
    "        return None\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns of phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Calculate the response\n",
    "        response = response.format(phrase)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define send_message()\n",
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    response = chitchat_response(message)\n",
    "    if response is not None:\n",
    "        print(\"BOT : {}\".format(response))\n",
    "        return state, None\n",
    "    \n",
    "    # Calculate the new_state, response, and pending_state\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret(message))]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))        \n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret(message))\n",
    "    return new_state, pending\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-12345\",\n",
    "    \"do you remember when I ordered 1000 kilos by accident?\",\n",
    "    \"kenyan\"\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with neural networks\n",
    "\n",
    "In this final exercise of the course, you're going to generate text using a neural network trained on the scripts of every episode of The Simpsons. Specifically, you'll use a simplified version of the sample_text() function that Alan described in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the seed text into the neural network\n",
    "seed = \"i'm gonna punch lenny in the back of the\"\n",
    "\n",
    "# Iterate over the different temperature values\n",
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(\"\\nGenerating text with riskiness : {}\\n\".format(temperature))\n",
    "    # Call the sample_text function\n",
    "    print(sample_text(seed, temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
